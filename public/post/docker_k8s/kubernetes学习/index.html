<!DOCTYPE html>
<html lang="zh-cn">
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
  <title>Kubernetes学习 - cr6588</title>
  <meta name="renderer" content="webkit" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>

<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />

<meta name="theme-color" content="#f8f5ec" />
<meta name="msapplication-navbutton-color" content="#f8f5ec">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="#f8f5ec">


<meta name="author" content="cr6588" /><meta name="description" content="1.minikube(主机非虚拟安装，否则直接跳过) 1.1 安装kubernetctl 1.3 安装virtualbox 1.2 安装minikube 1 2 3 4 5 6" /><meta name="keywords" content="Hugo, theme, even" />






<meta name="generator" content="Hugo 0.54.0 with even 4.0.0" />


<link rel="canonical" href="https://cr6588.github.io/post/docker_k8s/kubernetes%E5%AD%A6%E4%B9%A0/" />
<link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
<link rel="manifest" href="/manifest.json">
<link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5">

<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
<link href="/dist/even.c2a46f00.min.css" rel="stylesheet">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.1.20/dist/jquery.fancybox.min.css" integrity="sha256-7TyXnr2YU040zfSP+rEcz29ggW4j56/ujTPwjMzyqFY=" crossorigin="anonymous">


<meta property="og:title" content="Kubernetes学习" />
<meta property="og:description" content="1.minikube(主机非虚拟安装，否则直接跳过) 1.1 安装kubernetctl 1.3 安装virtualbox 1.2 安装minikube 1 2 3 4 5 6" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cr6588.github.io/post/docker_k8s/kubernetes%E5%AD%A6%E4%B9%A0/" />
<meta property="article:published_time" content="2018-09-18T10:20:11&#43;08:00"/>
<meta property="article:modified_time" content="2018-09-18T10:20:11&#43;08:00"/>

<meta itemprop="name" content="Kubernetes学习">
<meta itemprop="description" content="1.minikube(主机非虚拟安装，否则直接跳过) 1.1 安装kubernetctl 1.3 安装virtualbox 1.2 安装minikube 1 2 3 4 5 6">


<meta itemprop="datePublished" content="2018-09-18T10:20:11&#43;08:00" />
<meta itemprop="dateModified" content="2018-09-18T10:20:11&#43;08:00" />
<meta itemprop="wordCount" content="5622">



<meta itemprop="keywords" content="" />
<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Kubernetes学习"/>
<meta name="twitter:description" content="1.minikube(主机非虚拟安装，否则直接跳过) 1.1 安装kubernetctl 1.3 安装virtualbox 1.2 安装minikube 1 2 3 4 5 6"/>

<!--[if lte IE 9]>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/classlist/1.1.20170427/classList.min.js"></script>
<![endif]-->

<!--[if lt IE 9]>
  <script src="https://cdn.jsdelivr.net/npm/html5shiv@3.7.3/dist/html5shiv.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/respond.js@1.4.2/dest/respond.min.js"></script>
<![endif]-->

</head>
<body>
  <div id="mobile-navbar" class="mobile-navbar">
  <div class="mobile-header-logo">
    <a href="/" class="logo">cr6588</a>
  </div>
  <div class="mobile-navbar-icon">
    <span></span>
    <span></span>
    <span></span>
  </div>
</div>
<nav id="mobile-menu" class="mobile-menu slideout-menu">
  <ul class="mobile-menu-list">
    <a href="/">
        <li class="mobile-menu-item">Home</li>
      </a><a href="/post/">
        <li class="mobile-menu-item">归档</li>
      </a><a href="/categories/">
        <li class="mobile-menu-item">分类</li>
      </a><a href="/about">
        <li class="mobile-menu-item">关于</li>
      </a>
  </ul>
</nav>
  <div class="container" id="mobile-panel">
    <header id="header" class="header">
        <div class="logo-wrapper">
  <a href="/" class="logo">cr6588</a>
</div>

<nav class="site-navbar">
  <ul id="menu" class="menu">
    <li class="menu-item">
        <a class="menu-item-link" href="/">Home</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/post/">归档</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/categories/">分类</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/about">关于</a>
      </li>
  </ul>
</nav>
    </header>

    <main id="main" class="main">
      <div class="content-wrapper">
        <div id="content" class="content">
          <article class="post">
    
    <header class="post-header">
      <h1 class="post-title">Kubernetes学习</h1>

      <div class="post-meta">
        <span class="post-time"> 2018-09-18 </span>
        <div class="post-category">
            <a href="/categories/kubernetes/"> Kubernetes </a>
            </div>
          <span class="more-meta"> 约 5622 字 </span>
          <span class="more-meta"> 预计阅读 12 分钟 </span>
        <span id="busuanzi_container_page_pv" class="more-meta"> <span id="busuanzi_value_page_pv"><img src="/img/spinner.svg" alt="spinner.svg"/></span> 次阅读 </span>
      </div>
    </header>

    <div class="post-toc" id="post-toc">
  <h2 class="post-toc-title">文章目录</h2>
  <div class="post-toc-content always-active">
    <nav id="TableOfContents">
<ul>
<li>
<ul>
<li>
<ul>
<li>
<ul>
<li><a href="#1-minikube-主机非虚拟安装-否则直接跳过">1.minikube(主机非虚拟安装，否则直接跳过)</a>
<ul>
<li><a href="#1-1-安装kubernetctl-https-github-com-kubernetes-kubernetes-blob-master-changelog-1-12-md-client-binaries">1.1 <a href="https://github.com/kubernetes/kubernetes/blob/master/CHANGELOG-1.12.md#client-binaries">安装kubernetctl</a></a></li>
<li><a href="#1-3-安装virtualbox-https-www-cnblogs-com-wangshuyi-p-6927113-html">1.3 <a href="https://www.cnblogs.com/wangshuyi/p/6927113.html">安装virtualbox</a></a></li>
<li><a href="#1-2-安装minikube-https-github-com-kubernetes-minikube-releases">1.2 <a href="https://github.com/kubernetes/minikube/releases">安装minikube</a></a></li>
</ul></li>
<li><a href="#2-docker安装-18-06-1-ce-3-el7">2.docker安装（18.06.1.ce-3.el7）</a></li>
<li><a href="#3-kubeadm安装-1-12-2">3.kubeadm安装（1.12.2）</a></li>
<li><a href="#4-dashboard安装">4.dashboard安装</a></li>
<li><a href="#redis安装">redis安装</a></li>
<li><a href="#部署自己的应用">部署自己的应用</a>
<ul>
<li><a href="#配置secret拉取私有仓库镜像">配置secret拉取私有仓库镜像</a>
<ul>
<li><a href="#1-将密钥加载到yaml文件">1.将密钥加载到yaml文件</a></li>
<li><a href="#2-将secret直接加载到默认帐号中">2.将secret直接加载到默认帐号中</a></li>
</ul></li>
<li><a href="#启动应用后pod中容器不能通过域名访问外网">启动应用后pod中容器不能通过域名访问外网</a></li>
<li><a href="#容器需要使用host">容器需要使用host</a></li>
<li><a href="#statefulset应用">statefulset应用</a></li>
</ul></li>
<li><a href="#参考文献">参考文献</a></li>
</ul></li>
</ul></li>
</ul></li>
</ul>
</nav>
  </div>
</div>
    <div class="post-content">
      

<h4 id="1-minikube-主机非虚拟安装-否则直接跳过">1.minikube(主机非虚拟安装，否则直接跳过)</h4>

<h5 id="1-1-安装kubernetctl-https-github-com-kubernetes-kubernetes-blob-master-changelog-1-12-md-client-binaries">1.1 <a href="https://github.com/kubernetes/kubernetes/blob/master/CHANGELOG-1.12.md#client-binaries">安装kubernetctl</a></h5>

<h5 id="1-3-安装virtualbox-https-www-cnblogs-com-wangshuyi-p-6927113-html">1.3 <a href="https://www.cnblogs.com/wangshuyi/p/6927113.html">安装virtualbox</a></h5>

<h5 id="1-2-安装minikube-https-github-com-kubernetes-minikube-releases">1.2 <a href="https://github.com/kubernetes/minikube/releases">安装minikube</a></h5>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span></pre></td>
<td class="lntd">
<pre class="chroma">[root@cr6588 data]# minikube start
Starting local Kubernetes v1.10.0 cluster...
Starting VM...
E1113 10:59:55.111232    2586 start.go:168] Error starting host: Error creating host: Error executing step: Running precreate checks.
: We support Virtualbox starting with version 5. Your VirtualBox install is &#34;WARNING: The vboxdrv kernel module is not loaded. Either there is no module\n         available for the current kernel (3.10.0-862.el7.x86_64) or it failed to\n         load. Please recompile the kernel module and install it by\n\n           sudo /sbin/vboxconfig\n\n         You will not be able to start VMs until this problem is fixed.\n5.2.22r126460&#34;. Please upgrade at https://www.virtualbox.org.

/sbin/vboxconfig
yum install gcc  kernel-devel
cd /usr/src/kernels/
#mv 3.10.0-862.14.4.el7.x86_64 3.10.0-862.el7.x86_64

#vboxdrv.sh: Building VirtualBox kernel modules.
#grep: 不匹配的 ) 或 \)

#yum remove kernel-devel
#virtualbox需要本机kernel-devel对应的版本
yum install &#34;kernel-devel-uname-r == $(uname -r)&#34;

#没有开启虚拟化
[root@cr6588 kernels]# minikube start
Starting local Kubernetes v1.10.0 cluster...
Starting VM...
E1113 14:15:48.202789    3254 start.go:168] Error starting host: Error creating host: Error executing step: Running precreate checks.
: This computer doesn&#39;t have VT-X/AMD-v enabled. Enabling it in the BIOS is mandatory.</pre></td></tr></table>
</div>
</div>
<h4 id="2-docker安装-18-06-1-ce-3-el7">2.docker安装（18.06.1.ce-3.el7）</h4>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span></pre></td>
<td class="lntd">
<pre class="chroma"># 安装依赖包
yum install -y yum-utils device-mapper-persistent-data lvm2

# 添加Docker软件包源
yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo

#关闭测试版本list（只显示稳定版）
sudo yum-config-manager --enable docker-ce-edge
sudo yum-config-manager --enable docker-ce-test

# 更新yum包索引
yum makecache fast

#NO.1 直接安装Docker CE （will always install the highest  possible version，可能不符合你的需求）
yum install docker-ce

#NO.2 指定版本安装
yum list docker-ce --showduplicates|sort -r  
yum install docker-ce-18.06.1.ce-3.el7
#启动并加入服务
systemctl start docker &amp;&amp; systemctl enable docker
#设置私有registry
vi /etc/docker/daemon.json
{
    &#34;registry-mirrors&#34;: [&#34;https://xxx.com&#34;],
    &#34;insecure-registries&#34; : [&#34;ip:5000&#34;, &#34;xxxxxx.xx.cn:5000&#34;]
}
#重启生效
systemctl restart docker</pre></td></tr></table>
</div>
</div>
<h4 id="3-kubeadm安装-1-12-2">3.kubeadm安装（1.12.2）</h4>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span></pre></td>
<td class="lntd">
<pre class="chroma">#修改主机名称
hostnamectl set-hostname name
#关闭swap
swapoff -a
vi /etc/fstab
注释swap

systemctl stop firewalld
setenforce 0
sed -i &#39;s/^SELINUX=enforcing$/SELINUX=permissive/&#39; /etc/selinux/config
加载ipvs相关模块以及安装依赖关系
yum install ipset ipvsadm conntrack-tools.x86_64 -y

modprobe ip_vs_rr
modprobe ip_vs_wrr
modprobe ip_vs_sh
modprobe ip_vs</pre></td></tr></table>
</div>
</div>
<blockquote>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span><span class="lnt">8
</span></pre></td>
<td class="lntd">
<pre class="chroma">重启会失效，参考<span class="o">[</span>Linux启动自动加载模块<span class="o">](</span>https://www.jianshu.com/p/69e0430a7d20<span class="o">)</span>在/etc/sysconfig/modules/建立ipvs.modules并写入
<span class="cp">#!/bin/bash
</span><span class="cp"></span>modprobe ip_vs_rr
modprobe ip_vs_wrr
modprobe ip_vs_sh
modprobe ip_vs
给ipvs.modules加入执行权限
chmod +x ipvs.modules</pre></td></tr></table>
</div>
</div></blockquote>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span><span class="lnt">36
</span><span class="lnt">37
</span><span class="lnt">38
</span><span class="lnt">39
</span><span class="lnt">40
</span><span class="lnt">41
</span><span class="lnt">42
</span><span class="lnt">43
</span><span class="lnt">44
</span><span class="lnt">45
</span><span class="lnt">46
</span><span class="lnt">47
</span><span class="lnt">48
</span><span class="lnt">49
</span><span class="lnt">50
</span><span class="lnt">51
</span><span class="lnt">52
</span><span class="lnt">53
</span><span class="lnt">54
</span><span class="lnt">55
</span><span class="lnt">56
</span><span class="lnt">57
</span><span class="lnt">58
</span><span class="lnt">59
</span><span class="lnt">60
</span><span class="lnt">61
</span><span class="lnt">62
</span><span class="lnt">63
</span><span class="lnt">64
</span><span class="lnt">65
</span><span class="lnt">66
</span><span class="lnt">67
</span><span class="lnt">68
</span></pre></td>
<td class="lntd">
<pre class="chroma">查看是否成功
lsmod| grep ip_vs
2、开启内核转发，并使之生效，末尾EOF前不要有空格
cat &lt;&lt;EOF &gt;  /etc/sysctl.d/k8s.conf
net.bridge.bridge-nf-call-ip6tables = 1
net.bridge.bridge-nf-call-iptables = 1
EOF

sysctl -p /etc/sysctl.d/k8s.conf

cat &lt;&lt;EOF &gt; /etc/yum.repos.d/kubernetes.repo
[kubernetes]
name=Kubernetes
baseurl=http://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64
enabled=1
gpgcheck=0
repo_gpgcheck=0
gpgkey=http://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg
    http://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg
EOF

yum install kubelet-1.12.2-0 kubeadm-1.12.2-0 kubectl-1.12.2-0
#yum install kubelet kubeadm kubectl
systemctl enable kubelet &amp;&amp; systemctl start kubelet
# Run kubeadm config images pull prior to kubeadm init to verify connectivity to gcr.io registries.验证是否能拉取相关镜像，若不能则找到相关镜像库镜像拉取

kubeadm config images pull
#从私有库拉取相关镜像
docker login www.xxxx.cn:5000
#输入相用户密码
docker pull www.xxxx.cn:5000/k8s.gcr.io/kube-controller-manager:v1.12.2
docker pull www.xxxx.cn:5000/k8s.gcr.io/kube-apiserver:v1.12.2
docker pull www.xxxx.cn:5000/k8s.gcr.io/kube-scheduler:v1.12.2
docker pull www.xxxx.cn:5000/k8s.gcr.io/etcd:3.2.24
docker pull www.xxxx.cn:5000/k8s.gcr.io/coredns:1.2.2
docker pull www.xxxx.cn:5000/k8s.gcr.io/pause:3.1
docker pull www.xxxx.cn:5000/k8s.gcr.io/kube-proxy:v1.12.2

docker tag www.xxxx.cn:5000/k8s.gcr.io/kube-controller-manager:v1.12.2 k8s.gcr.io/kube-controller-manager:v1.12.2
docker tag www.xxxx.cn:5000/k8s.gcr.io/kube-apiserver:v1.12.2 k8s.gcr.io/kube-apiserver:v1.12.2 
docker tag www.xxxx.cn:5000/k8s.gcr.io/kube-scheduler:v1.12.2 k8s.gcr.io/kube-scheduler:v1.12.2
docker tag www.xxxx.cn:5000/k8s.gcr.io/etcd:3.2.24 k8s.gcr.io/etcd:3.2.24
docker tag www.xxxx.cn:5000/k8s.gcr.io/coredns:1.2.2 k8s.gcr.io/coredns:1.2.2
docker tag www.xxxx.cn:5000/k8s.gcr.io/pause:3.1 k8s.gcr.io/pause:3.1
docker tag www.xxxx.cn:5000/k8s.gcr.io/kube-proxy:v1.12.2 k8s.gcr.io/kube-proxy:v1.12.2
#确认相关镜像在主从上都存在，否则有可能后面虽然加入节点成功，但一直是notready状态
#master节点执行，network使用flannel前置条件.若需要制定版本则加入--kubernetes-version=v1.12.2
kubeadm init --pod-network-cidr=10.244.0.0/16
#master节点执行，network使用calico前置条件.若需要制定版本则加入
kubeadm init --pod-network-cidr=192.168.0.0/16
#master节点执行，network使用weave net前置条件
kubeadm init
#出错时还原
kubeadm reset
#记录下从节点加入命令
kubeadm join xxx:6443 --token gd7nxxxxxx --discovery-token-ca-cert-hash sha256:xxxx
#To make kubectl work for your non-root user, run these commands, which are also part of the kubeadm init output:
mkdir -p $HOME/.kube
sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
sudo chown $(id -u):$(id -g) $HOME/.kube/config
# Alternatively, if you are the root user, you can run:
export KUBECONFIG=/etc/kubernetes/admin.conf

#使用flannel（不支持NetworkPolicy,部署的应用会无视firewalld完全暴露在公网中）
sysctl net.bridge.bridge-nf-call-iptables=1
kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/bc79dd1505b0c8681ece4de4c0d86c5cd2643275/Documentation/kube-flannel.yml
#使用calico
kubectl apply -f https://docs.projectcalico.org/v3.3/getting-started/kubernetes/installation/hosted/rbac-kdd.yaml</pre></td></tr></table>
</div>
</div>
<p>kubectl apply -f <a href="https://docs.projectcalico.org/v3.3/getting-started/kubernetes/installation/hosted/kubernetes-datastore/calico-networking/1.7/calico.yaml">https://docs.projectcalico.org/v3.3/getting-started/kubernetes/installation/hosted/kubernetes-datastore/calico-networking/1.7/calico.yaml</a>
    #使用weave net
    kubectl apply -f &ldquo;<a href="https://cloud.weave.works/k8s/net?k8s-version=$(kubectl">https://cloud.weave.works/k8s/net?k8s-version=$(kubectl</a> version | base64 | tr -d &lsquo;\n&rsquo;)&rdquo;
    #查看状态
    kubectl get pods &ndash;all-namespaces</p>

<blockquote>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span></pre></td>
<td class="lntd">
<pre class="chroma">...failed to set bridge addr: &#34;cni0&#34; already has an IP address different from 10.244.1.1/24
删除cni0网卡（ip link delete cni0）可以解决，但为了预防以后莫名错误，完全重置一次，参见https://github.com/kubernetes/kubernetes/issues/39557
kubeadm reset
systemctl stop kubelet
systemctl stop docker
rm -rf /var/lib/cni/
rm -rf /var/lib/kubelet/*
rm -rf /etc/cni/
ifconfig cni0 down
ifconfig flannel.1 down
ifconfig docker0 down
ip link delete cni0
ip link delete flannel.1
ifconfig docker0 up
systemctl start docker
systemctl start kubelet

...Readiness probe failed: calico/node is not ready: BIRD is not ready: BGP not established with 10.192.0.1
calico健康检查出错，calico的ip自动检测给了一个错误IP10.192.0.1，在将https://docs.projectcalico.org/v3.3/getting-started/kubernetes/installation/hosted/kubernetes-datastore/calico-networking/1.7/calico.yaml下载下来，在calico-node的env加入IP_AUTODETECTION_METHOD,其eth.*视其节点间通信的网卡决定</pre></td></tr></table>
</div>
</div></blockquote>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span></pre></td>
<td class="lntd">
<pre class="chroma">...
            - name: IP
              value: &#34;autodetect&#34;
            - name: IP_AUTODETECTION_METHOD
              value: &#34;interface=eth.*&#34;
...</pre></td></tr></table>
</div>
</div><div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span></pre></td>
<td class="lntd">
<pre class="chroma">#主节点向指定ip开放相关端口
firewall-cmd --permanent --add-rich-rule=&#34;rule family=&#34;ipv4&#34; source address=&#34;www.xxxx.cn&#34; port protocol=&#34;tcp&#34; port=&#34;6443&#34; accept&#34;
firewall-cmd --permanent --add-rich-rule=&#34;rule family=&#34;ipv4&#34; source address=&#34;www.xxxx.cn&#34; port protocol=&#34;tcp&#34; port=&#34;2379-2380&#34; accept&#34;
firewall-cmd --permanent --add-rich-rule=&#34;rule family=&#34;ipv4&#34; source address=&#34;www.xxxx.cn&#34; port protocol=&#34;tcp&#34; port=&#34;10250-10252&#34; accept&#34;
#从节点向指定ip开放相关端口
firewall-cmd --permanent --add-rich-rule=&#34;rule family=&#34;ipv4&#34; source address=&#34;www.xxxx.cn&#34; port protocol=&#34;tcp&#34; port=&#34;10250&#34; accept&#34;
firewall-cmd --permanent --add-rich-rule=&#34;rule family=&#34;ipv4&#34; source address=&#34;www.xxxx.cn&#34; port protocol=&#34;tcp&#34; port=&#34;30000-32767&#34; accept&#34;
#默认主节点不会编排容器，若希望启用则运行
kubectl taint nodes --all node-role.kubernetes.io/master-
#从节点加入主节点
#修改节点名称
hostnamectl --static set-hostname [主机名]
#在node的hosts文件加入解析
127.0.0.1 localhost [主机名]
#使用刚刚的kubeadm join
kubeadm join xxx:6443 --token gd7nxxxxxx --discovery-token-ca-cert-hash sha256:xxxx
#token有效期24小时，过期之后用创建token，查找hash值即可
kubeadm token create
kubeadm token list
openssl x509 -pubkey -in /etc/kubernetes/pki/ca.crt | openssl rsa -pubin -outform der 2&gt;/dev/null | openssl dgst -sha256 -hex | sed &#39;s/^.* //&#39;
#主节点查看节点信息
kubectl get nodes</pre></td></tr></table>
</div>
</div>
<blockquote>
<p>init之后如果关机重启kubelet正常的话，root用户若使用kubelctl提示无法连接则
export KUBECONFIG=/etc/kubernetes/admin.conf</p>
</blockquote>

<h4 id="4-dashboard安装">4.dashboard安装</h4>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span><span class="lnt">36
</span><span class="lnt">37
</span><span class="lnt">38
</span><span class="lnt">39
</span><span class="lnt">40
</span><span class="lnt">41
</span><span class="lnt">42
</span><span class="lnt">43
</span><span class="lnt">44
</span><span class="lnt">45
</span><span class="lnt">46
</span><span class="lnt">47
</span><span class="lnt">48
</span><span class="lnt">49
</span><span class="lnt">50
</span><span class="lnt">51
</span><span class="lnt">52
</span><span class="lnt">53
</span><span class="lnt">54
</span><span class="lnt">55
</span><span class="lnt">56
</span><span class="lnt">57
</span><span class="lnt">58
</span><span class="lnt">59
</span><span class="lnt">60
</span><span class="lnt">61
</span><span class="lnt">62
</span><span class="lnt">63
</span><span class="lnt">64
</span><span class="lnt">65
</span><span class="lnt">66
</span><span class="lnt">67
</span><span class="lnt">68
</span><span class="lnt">69
</span><span class="lnt">70
</span><span class="lnt">71
</span><span class="lnt">72
</span></pre></td>
<td class="lntd">
<pre class="chroma">#由于执行过一次最简安装后无法访问本地，查看kubectl get pods --all-namespaces
kube-system   kube-scheduler-localhost.localdomain            1/1     Running             0          91m
kube-system   kubernetes-dashboard-77fd78f978-4vzk2           0/1     ContainerCreating   0          13m
一直处于ContainerCreating中，于是删除,又通过自检证书方式重建
kubectl delete -f https://raw.githubusercontent.com/kubernetes/dashboard/master/src/deploy/recommended/kubernetes-dashboard.yaml
#创建自已的证书
openssl req \
-newkey rsa:4096 -nodes -sha256 -keyout certs/dashboard.key \
-x509 -days 365 -out certs/dashboard.crt

kubectl create secret generic kubernetes-dashboard-certs --from-file=$HOME/certs -n kube-system

kubectl apply -f https://raw.githubusercontent.com/kubernetes/dashboard/master/src/deploy/recommended/kubernetes-dashboard.yaml
#查看服务，发现服务运行但无法访问
kubectl get service kubernetes-dashboard -n kube-system
#删除
kubectl delete -f https://raw.githubusercontent.com/kubernetes/dashboard/master/src/deploy/recommended/kubernetes-dashboard.yaml
#下载文件
curl -O https://raw.githubusercontent.com/kubernetes/dashboard/master/src/deploy/recommended/kubernetes-dashboard.yaml
#在kubernetes-dashboard.yaml中添加service的type为NodePort
...
  namespace: kube-system
spec:
    type: NodePort
    ports:
        - port: 443
...
#重新生成密钥并部署
kubectl create secret generic kubernetes-dashboard-certs --from-file=$HOME/certs -n kube-system
kubectl apply -f kubernetes-dashboard.yaml
#查看服务映射的本地端口
kubectl get service kubernetes-dashboard -n kube-system
NAME                   TYPE       CLUSTER-IP       EXTERNAL-IP   PORT(S)         AGE
kubernetes-dashboard   NodePort   10.109.126.132   &lt;none&gt;        443:31474/TCP   20m
#访问子节点https://ip:31474, 需要登录。若没有登录界面，直接进入，访问https://192.168.199.206:31474/#!/login
![x](/images/k8s_login.png)
#创建用户
cat &lt;&lt;EOF &gt; dashboard-adminuser.yaml

apiVersion: v1
kind: ServiceAccount
metadata:
  name: admin-user
  namespace: kube-system
---
apiVersion: rbac.authorization.k8s.io/v1beta1
kind: ClusterRoleBinding
metadata:
  name: admin-user
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: cluster-admin
subjects:
- kind: ServiceAccount
  name: admin-user
  namespace: kube-system
EOF

kubectl apply -f dashboard-adminuser.yaml
#查找，复制admin-user的token，登录即可
kubectl -n kube-system describe secret $(kubectl -n kube-system get secret | grep admin-user | awk &#39;{print $1}&#39;)

#查看日志
kubectl describe pod kubernetes-dashboard-77fd78f978-4vzk2无法查看描述必须加上--namespace=kube-system
kubectl describe pod kubernetes-dashboard-77fd78f978-4vzk2 --namespace=kube-system
kubectl logs kubernetes-dashboard-77fd78f978-4vzk2 -n kube-system

...failed to set bridge addr: &#34;cni0&#34; already has an IP address different from 10.244.1.1/24

kubectl get pods --all-namespaces
kubectl get service kubernetes-dashboard -n kube-system</pre></td></tr></table>
</div>
</div>
<blockquote>
<p>使用flannel启用防火墙后dashboard可能无法安装，需要开启
    firewall-cmd &ndash;permanent &ndash;add-masquerade # 允许防火墙伪装
并开启相关端口，参照<a href="https://kubernetes.io/docs/setup/independent/install-kubeadm/">install-kubeadm</a>开启
使用calico必须启用防火墙，需要开启
    firewall-cmd &ndash;permanent &ndash;add-masquerade # 允许防火墙伪装
并开启相关端口，参照<a href="https://docs.projectcalico.org/v3.3/getting-started/kubernetes/requirements">System requirements</a>开启
5473需要开启否则应用内部无法通过服务名:端口访问
使用weave-net必须启用防火墙，需要开启
    firewall-cmd &ndash;permanent &ndash;add-masquerade # 允许防火墙伪装
并开启相关端口，参照<a href="https://www.weave.works/docs/net/latest/faq/">FAQ</a>开启
TCP 6783-6784 and UDP 6783-6784需要开启否则应用内部通过服务名:端口访问会时快时慢</p>
</blockquote>

<h4 id="redis安装">redis安装</h4>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><span class="lnt">1
</span></pre></td>
<td class="lntd">
<pre class="chroma">参见docker hub中[redis](https://hub.docker.com/_/redis/)官方镜像文档说明，直接在dashboard上进行图形化安装</pre></td></tr></table>
</div>
</div>
<blockquote>
<p>安装后查看服务的yaml文档中的端口发现
        &ldquo;protocol&rdquo;: &ldquo;TCP&rdquo;,
        &ldquo;port&rdquo;: 6388,
        &ldquo;targetPort&rdquo;: 6379,
        &ldquo;nodePort&rdquo;: 31783
其中port是集群内部的端口，31783是节点以及外部可以访问的端口，6388是pod的端口，也就是若外网链接访问时首先经过31783进入然后经过6388最后指向6379。使用kubectl expose deployment/redis &ndash;type=&ldquo;NodePort&rdquo; &ndash;port 6379创建service时，port与targetPort都会是6379</p>
</blockquote>

<p>图形化安装之后删除,创建redis持久化安装</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><span class="lnt">1
</span><span class="lnt">2
</span></pre></td>
<td class="lntd">
<pre class="chroma">#创建pv与pvc
vi redis-pv.yaml</pre></td></tr></table>
</div>
</div><div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span></pre></td>
<td class="lntd">
<pre class="chroma">kind: PersistentVolume
apiVersion: v1
metadata:
  name: mysql-pv-volume
  labels:
    type: local
spec:
  storageClassName: manual
  capacity:
    storage: 20Gi
  accessModes:
    - ReadWriteOnce
  hostPath:
    path: &#34;/mnt/data&#34;
---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: mysql-pv-claim
spec:
  storageClassName: manual
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 20Gi</pre></td></tr></table>
</div>
</div><div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span><span class="lnt">36
</span><span class="lnt">37
</span><span class="lnt">38
</span><span class="lnt">39
</span><span class="lnt">40
</span><span class="lnt">41
</span><span class="lnt">42
</span><span class="lnt">43
</span><span class="lnt">44
</span><span class="lnt">45
</span><span class="lnt">46
</span><span class="lnt">47
</span><span class="lnt">48
</span><span class="lnt">49
</span><span class="lnt">50
</span><span class="lnt">51
</span><span class="lnt">52
</span><span class="lnt">53
</span><span class="lnt">54
</span><span class="lnt">55
</span><span class="lnt">56
</span><span class="lnt">57
</span><span class="lnt">58
</span><span class="lnt">59
</span><span class="lnt">60
</span></pre></td>
<td class="lntd">
<pre class="chroma">kubectl create -f redis-pv.yaml
#会在从节点生成/data/redis-data目录

#创建deployment
{
  &#34;kind&#34;: &#34;Deployment&#34;,
  &#34;apiVersion&#34;: &#34;extensions/v1beta1&#34;,
  &#34;metadata&#34;: {
    &#34;name&#34;: &#34;redis-persistent&#34;,
    &#34;namespace&#34;: &#34;default&#34;,
    &#34;labels&#34;: {
      &#34;k8s-app&#34;: &#34;redis-persistent&#34;
    }
  },
  &#34;spec&#34;: {
    &#34;replicas&#34;: 1,
    &#34;selector&#34;: {
      &#34;matchLabels&#34;: {
        &#34;k8s-app&#34;: &#34;redis-persistent&#34;
      }
    },
    &#34;template&#34;: {
      &#34;metadata&#34;: {
        &#34;name&#34;: &#34;redis-persistent&#34;,
        &#34;labels&#34;: {
          &#34;k8s-app&#34;: &#34;redis-persistent&#34;
        }
      },
      &#34;spec&#34;: {
        &#34;containers&#34;: [
          {
            &#34;name&#34;: &#34;redis-persistent&#34;,
            &#34;image&#34;: &#34;redis:5&#34;,
            &#34;command&#34;: [
              &#34;redis-server&#34;
            ],
            &#34;args&#34;: [
              &#34;--appendonly yes&#34;
            ],
            &#34;volumeMounts&#34;: [
              {
                &#34;name&#34;: &#34;redis-persistent-storage&#34;,
                &#34;mountPath&#34;: &#34;/data&#34;
              }
            ]
          }
        ],
        &#34;volumes&#34;: [
          {
            &#34;name&#34;: &#34;redis-persistent-storage&#34;,
            &#34;persistentVolumeClaim&#34;: {
              &#34;claimName&#34;: &#34;redis-pv-claim&#34;
            }
          }
        ]
      }
    }
  }
}
#当要使用自己的redis.conf时将自己的conf文件复制到从节点/data/redis-data下，args改为/data/xxx.conf即可</pre></td></tr></table>
</div>
</div>
<blockquote>
<p>挂载磁盘时注意路径，不要将磁盘挂载到镜像本身就有的路径，例如/data中本身含有应用相关文件，然后又挂载到/data时，会覆盖镜像已有的data</p>
</blockquote>

<h4 id="部署自己的应用">部署自己的应用</h4>

<p>在创建好自己的镜像并上传上去后，通过dashboard安装时发现镜像始终无法拉取。但是通过docker直接拉取私有镜像时可以的。搜寻一番之后发现是k8s拉取私有镜像时需要docker相关账号信息。</p>

<h5 id="配置secret拉取私有仓库镜像">配置secret拉取私有仓库镜像</h5>

<p>kubectl create secret docker-registry registrysecret &ndash;docker-server=ip或域名:端口号  &ndash;docker-username=admin &ndash;docker-password=xxxx
有2种方式加载secret</p>

<h6 id="1-将密钥加载到yaml文件">1.将密钥加载到yaml文件</h6>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span></pre></td>
<td class="lntd">
<pre class="chroma">apiVersion: v1
kind: ReplicationController
metadata:
  name: webapp
spec:
  replicas: 2
  template:
    metadata:
      name: webapp
      labels:
        app: webapp
    spec:
      containers:
      - name: webapp
        imagePullPolicy: Always
        image: e5:8889/tomcat:latest
        ports:
          - containerPort: 80
      imagePullSecrets:
      - name: registrysecret</pre></td></tr></table>
</div>
</div>
<h6 id="2-将secret直接加载到默认帐号中">2.将secret直接加载到默认帐号中</h6>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span></pre></td>
<td class="lntd">
<pre class="chroma">kubectl patch serviceaccount default -p &#39;{&#34;imagePullSecrets&#34;: [{&#34;name&#34;: &#34;registrysecret&#34;}]}&#39;
#查看帐号配置
kubectl get serviceaccounts default -o yaml
#在dashboard更改下版本或者删除重建部署即可</pre></td></tr></table>
</div>
</div>
<h5 id="启动应用后pod中容器不能通过域名访问外网">启动应用后pod中容器不能通过域名访问外网</h5>

<p>#进入容器查看
  kubectl get pods
  kubectl kubectl exec -it pod名称 &ndash; /bin/bash
  #退出
  crtl+p &amp;&amp; crtl+q</p>

<blockquote>
<p>如果Pod具有多个Container，请使用&ndash;container或-c在kubectl exec命令中指定Container 。例如，假设您有一个名为my-pod的Pod，而Pod有两个名为main-app和helper-app的容器。以下命令将打开主应用程序Container的shell。</p>
</blockquote>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><span class="lnt">1
</span><span class="lnt">2
</span></pre></td>
<td class="lntd">
<pre class="chroma">#交互模式进入容器
kubectl exec -it my-pod --container main-app -- /bin/bash</pre></td></tr></table>
</div>
</div>
<p>网上搜索一番发现在<a href="https://github.com/kubernetes/kubernetes/issues/57096#issuecomment-351029125中看到是防火墙未开启udp端口的问题，但具体是哪一个端口不能确定，经过同事之前更改dns服务器之后就能在容器中ping通，应该是dns问题，在容器中更改/etc/resolv.conf之后发现可以ping通，但不能每次容器都要去更改吧，也不应该这样做，所以又寻找其它方法，又搜索了很久发现很多人都遇到过这个问题，一部分是通过sysctl">https://github.com/kubernetes/kubernetes/issues/57096#issuecomment-351029125中看到是防火墙未开启udp端口的问题，但具体是哪一个端口不能确定，经过同事之前更改dns服务器之后就能在容器中ping通，应该是dns问题，在容器中更改/etc/resolv.conf之后发现可以ping通，但不能每次容器都要去更改吧，也不应该这样做，所以又寻找其它方法，又搜索了很久发现很多人都遇到过这个问题，一部分是通过sysctl</a> net.bridge.bridge-nf-call-iptables=1可以恢复，但测试之后未能成功。在搜索过程看到一些处理这个问题的过程是弄清ping之后请求的走向，通过查看防火墙日志确定在哪一过程被拦截，但这方面积累比较薄弱，且dns的容器无法进入，于是又继续查找。之后把防火墙关了重启服务器发现可以ping通,kubectl exec my-pod ping www.baidu.com,认为是防火墙端口的问题，而dns是coredns是通过安装flanel带来的，最后去flanel的<a href="https://github.com/coreos/flannel/blob/master/Documentation/troubleshooting.md#firewalls">Troubleshooting</a>的中firewalls指出</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><span class="lnt">1
</span><span class="lnt">2
</span></pre></td>
<td class="lntd">
<pre class="chroma">When using udp backend, flannel uses UDP port 8285 for sending encapsulated packets.
When using vxlan backend, kernel uses UDP port 8472 for sending encapsulated packets.</pre></td></tr></table>
</div>
</div>
<p>但不能确定是哪一个就一个个测试，最终发现在节点启用8472/udp后，在master执行</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span></pre></td>
<td class="lntd">
<pre class="chroma">systemctl daemon-reload
systemctl restart kubelet
systemctl restart docker</pre></td></tr></table>
</div>
</div>
<p>master再kubectl exec my-pod ping www.baidu.com就能ping通，但速度较慢，在master也启用8472/udp后ping的速度明显加快</p>

<blockquote>
<p>回顾整个过程可以发现在最初是找对方向的，但之后又跑偏了，说明对k8s的网络管理方面理解的很薄弱，然后对centos7如何监控请求走向还是不会，待提高的地方很多。</p>
</blockquote>

<h5 id="容器需要使用host">容器需要使用host</h5>

<p>在只有docker时可以通过docker run时加入&ndash;add-host=&ldquo;localhost example.com&rdquo;:127.0.0.1，而在k8s时可以在pod的<a href="https://kubernetes.io/docs/concepts/services-networking/add-entries-to-pod-etc-hosts-with-host-aliases/">spec.hostAliases</a>实现。eg:</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span></pre></td>
<td class="lntd">
<pre class="chroma">...
    spec:
  hostAliases:
  - ip: &#34;10.101.4.13&#34;
    hostnames:
    - &#34;xxx.xx.xx&#34;
  - ip: &#34;xxx.xx.xx.xxx&#34;
    hostnames:
    - &#34;user.xx.xxx.cn&#34;
  - ip: &#34;118.xxx.xx.xxx&#34;
    hostnames:
    - &#34;picture.xxx.cn&#34;
    - &#34;static.xxx.cn&#34;
  containers:
  - name: ...
  ...</pre></td></tr></table>
</div>
</div>
<h5 id="statefulset应用">statefulset应用</h5>

<p>有状态应用于headless service搭配，它的主要特点是ClusterIP为None,以一个zookeeper应用为例</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span><span class="lnt">36
</span><span class="lnt">37
</span><span class="lnt">38
</span><span class="lnt">39
</span><span class="lnt">40
</span><span class="lnt">41
</span><span class="lnt">42
</span><span class="lnt">43
</span><span class="lnt">44
</span><span class="lnt">45
</span><span class="lnt">46
</span><span class="lnt">47
</span><span class="lnt">48
</span><span class="lnt">49
</span><span class="lnt">50
</span><span class="lnt">51
</span><span class="lnt">52
</span><span class="lnt">53
</span><span class="lnt">54
</span><span class="lnt">55
</span><span class="lnt">56
</span><span class="lnt">57
</span><span class="lnt">58
</span></pre></td>
<td class="lntd">
<pre class="chroma">kind: PersistentVolume
apiVersion: v1
metadata:
  name: zookeeper-pv-0
spec:
  capacity:
    storage: 1Gi
  accessModes:
    - ReadWriteOnce
  hostPath:
    path: &#34;/docker/pv/zookeeper&#34;
---
apiVersion: v1
kind: Service
metadata:
  name: zookeeper
  labels:
    app: zookeeper
spec:
  ports:
  - port: 2181
    name: zookeeper
  clusterIP: None
  selector:
    app: zookeeper
---
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: zookeeper
spec:
  serviceName: &#34;zookeeper&#34;
  replicas: 1
  selector:
    matchLabels:
      app: zookeeper
  template:
    metadata:
      labels:
        app: zookeeper
    spec:
      containers:
      - name: zookeeper
        image: zookeeper
        ports:
        - containerPort: 2181
          name: zookeeper
        volumeMounts:
        - name: zk
          mountPath: /data
  volumeClaimTemplates:
  - metadata:
      name: zk
    spec:
      accessModes: [ &#34;ReadWriteOnce&#34; ]
      resources:
        requests:
          storage: 1Gi</pre></td></tr></table>
</div>
</div>
<p>由于未配置动态存储，先设置一个hostPath类型的pv，然后设置headless service,最后设置StatefulSet，其中volumeClaimTemplates中描述了pvc，会查询符合要求的pv后自动创建pvc,在StatefulSet中pod与pvc会绑定，当伸缩数量为2时，需要新建pv满足</p>

<h4 id="参考文献">参考文献</h4>

<ol>
<li><a href="https://kubernetes.io/docs/setup/independent/install-kubeadm/">https://kubernetes.io/docs/setup/independent/install-kubeadm/</a></li>
<li><a href="https://www.cnblogs.com/crysmile/p/9648406.html">https://www.cnblogs.com/crysmile/p/9648406.html</a></li>
<li><a href="http://blog.51cto.com/11887934/2050590">http://blog.51cto.com/11887934/2050590</a></li>
<li><a href="https://kubernetes.io/docs/tasks/debug-application-cluster/get-shell-running-container/">https://kubernetes.io/docs/tasks/debug-application-cluster/get-shell-running-container/</a></li>
</ol>

    </div>

    <div class="post-copyright">
  
  <p class="copyright-item">
    <span class="item-title">上次更新</span>
    <span class="item-content">
        2018-09-18
        
    </span>
  </p>
  
  
</div>
<footer class="post-footer">
      
      <nav class="post-nav">
        <a class="prev" href="/post/docker_k8s/docker%E4%B8%8Ek8s%E7%AE%80%E4%BB%8B/">
            <i class="iconfont icon-left"></i>
            <span class="prev-text nav-default">Docker与k8s简介</span>
            <span class="prev-text nav-mobile">上一篇</span>
          </a>
        <a class="next" href="/post/docker_k8s/kubernetes%E5%AE%9E%E9%AA%8C/">
            <span class="next-text nav-default">Kubernetes实验</span>
            <span class="next-text nav-mobile">下一篇</span>
            <i class="iconfont icon-right"></i>
          </a>
      </nav>
    </footer>
  </article>
        </div>
        <div id="disqus_thread"></div>
    <script type="text/javascript">
    (function() {
      
      
      if (window.location.hostname === 'localhost') return;

      var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
      var disqus_shortname = 'https-cr6588-github-io';
      dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
    </script>
    <noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>

      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="social-links">
      <a href="mailto:cr6588@vip.qq.com" class="iconfont icon-email" title="email"></a>
      <a href="https://github.com/cr6588" class="iconfont icon-github" title="github"></a>
  
    
  
</div>

<div class="copyright">
  <span class="power-by">
    由 <a class="hexo-link" href="https://gohugo.io">Hugo</a> 强力驱动
  </span>
  <span class="division">|</span>
  <span class="theme-info">
    主题 - 
    <a class="theme-link" href="https://github.com/olOwOlo/hugo-theme-even">Even</a>
  </span>

  <div class="busuanzi-footer">
    <span id="busuanzi_container_site_pv"> 本站总访问量 <span id="busuanzi_value_site_pv"><img src="/img/spinner.svg" alt="spinner.svg"/></span> 次 </span>
      <span class="division">|</span>
    <span id="busuanzi_container_site_uv"> 本站总访客数 <span id="busuanzi_value_site_uv"><img src="/img/spinner.svg" alt="spinner.svg"/></span> 人 </span>
  </div>

  <span class="copyright-year">
    &copy; 
    2019
    <span class="heart">
      <i class="iconfont icon-heart"></i>
    </span>
    <span class="author">cr6588</span>
  </span>
</div>
    </footer>

    <div class="back-to-top" id="back-to-top">
      <i class="iconfont icon-up"></i>
    </div>
  </div>
  
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.2.1/dist/jquery.min.js" integrity="sha256-hwg4gsxgFZhOsEEamdOYGBf13FyQuiTwlAQgxVSNgt4=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/slideout@1.0.1/dist/slideout.min.js" integrity="sha256-t+zJ/g8/KXIJMjSVQdnibt4dlaDxc9zXr/9oNPeWqdg=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.1.20/dist/jquery.fancybox.min.js" integrity="sha256-XVLffZaxoWfGUEbdzuLi7pwaUJv1cecsQJQqGLe7axY=" crossorigin="anonymous"></script>
<script type="text/javascript" src="/dist/even.26188efa.min.js"></script>








</body>
</html>
